{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507decf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear all\n",
    "%reset -f\n",
    "\n",
    "#import packages\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import mne\n",
    "import matplotlib\n",
    "from sklearn.utils import resample\n",
    "from mne_icalabel import label_components\n",
    "\n",
    "root = 'F:/Documents/Science/MirRevAdaptEEG'\n",
    "participants = list(range(0,32))\n",
    "#specify which erp we are analyzing\n",
    "erps = 'lrp'\n",
    "\n",
    "#pop up plots as separate window & interactive\n",
    "%matplotlib qt\n",
    "matplotlib.pyplot.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6a9522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we get the 800 timepoints we are considering as a list, to use for indices given by cluster-based permutation later\n",
    "root_directory = root\n",
    "data_directory = os.path.join(root_directory, 'data/eeg/')\n",
    "pp = 0 #only need one participant\n",
    "\n",
    "# we can use aligned data, any movement condition (e.g. leftmoves)\n",
    "\n",
    "id_directory = os.path.join(data_directory, 'p%03d/' % pp)\n",
    "pp_directory = os.path.join(id_directory, erps)\n",
    "fname = os.path.join(pp_directory, 'p%03d_SmallLarge_%s_%s_%s-ave.fif' % (pp, 'leftmoves', 'SL', 'aligned'))\n",
    "evoked = mne.read_evokeds(fname)\n",
    "df = evoked[0].to_data_frame()\n",
    "time = df['time'].tolist()\n",
    "time = time[200:401] #get only timepoints we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a164b297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for each condition\n",
    "# Create separate lists for C3 and C4, along with right and left movements, so that we may calculate for LRPs\n",
    "# transform data into array accepted for cluster-based permutation test in mne\n",
    "# output: (n_participants, n_timepts) for each condition\n",
    "\n",
    "root_directory = root\n",
    "data_directory = os.path.join(root_directory, 'data/eeg/')\n",
    "\n",
    "# #specify channels we need - LRP\n",
    "channels = ['C3', 'C4']\n",
    "\n",
    "#ALIGNED\n",
    "#read in evoked object\n",
    "movenames = ['rightmoves', 'leftmoves']\n",
    "\n",
    "for channel in range(0, len(channels)):\n",
    "    for move in range(0, len(movenames)):\n",
    "        evoked_list = []\n",
    "        for pp in participants:\n",
    "            id_directory = os.path.join(data_directory, 'p%03d/' % participants[pp])\n",
    "            pp_directory = os.path.join(id_directory, erps)\n",
    "            fname = os.path.join(pp_directory, 'p%03d_SmallLarge_%s_%s_%s-ave.fif' % (participants[pp], movenames[move], 'SL', 'aligned'))\n",
    "            evoked = mne.read_evokeds(fname)\n",
    "            evoked = evoked[0]\n",
    "            evoked = evoked.get_data(picks=channels[channel]) #will give data of shape (n_channels, n_timepts)\n",
    "            evoked = evoked[0] #get first list then index timepts below\n",
    "            evoked = evoked[200:401] #get timepts we are interested in\n",
    "            evoked_list.append(evoked)\n",
    "        if move == 0 and channel == 0:\n",
    "            aln_right_C3 = evoked_list\n",
    "        elif move == 0 and channel == 1:\n",
    "            aln_right_C4 = evoked_list\n",
    "        elif move == 1 and channel == 0:\n",
    "            aln_left_C3 = evoked_list\n",
    "        elif move == 1 and channel == 1:\n",
    "            aln_left_C4 = evoked_list\n",
    "            \n",
    "#ALIGNED FOR ROTATION\n",
    "movenames = ['rightmoves', 'leftmoves']\n",
    "\n",
    "for channel in range(0, len(channels)):\n",
    "    for move in range(0, len(movenames)):\n",
    "        evoked_list = []\n",
    "        for pp in participants:\n",
    "            id_directory = os.path.join(data_directory, 'p%03d/' % participants[pp])\n",
    "            pp_directory = os.path.join(id_directory, erps)\n",
    "            fname = os.path.join(pp_directory, 'p%03d_SmallLarge_%s_%s_%s-ave.fif' % (participants[pp], movenames[move], 'SL', 'aln_rot'))\n",
    "            if os.path.isfile(fname) == False:\n",
    "                continue\n",
    "            evoked = mne.read_evokeds(fname)\n",
    "            evoked = evoked[0]\n",
    "            evoked = evoked.get_data(picks=channels[channel]) #will give data of shape (n_channels, n_timepts)\n",
    "            evoked = evoked[0] #get first list then index timepts below\n",
    "            evoked = evoked[200:401] #get timepts we are interested in\n",
    "            evoked_list.append(evoked)\n",
    "        if move == 0 and channel == 0:\n",
    "            alnrot_right_C3 = evoked_list\n",
    "        elif move == 0 and channel == 1:\n",
    "            alnrot_right_C4 = evoked_list\n",
    "        elif move == 1 and channel == 0:\n",
    "            alnrot_left_C3 = evoked_list\n",
    "        elif move == 1 and channel == 1:\n",
    "            alnrot_left_C4 = evoked_list\n",
    "            \n",
    "#ALIGNED FOR MIRROR\n",
    "movenames = ['rightmoves', 'leftmoves']\n",
    "\n",
    "for channel in range(0, len(channels)):\n",
    "    for move in range(0, len(movenames)):\n",
    "        evoked_list = []\n",
    "        for pp in participants:\n",
    "            id_directory = os.path.join(data_directory, 'p%03d/' % participants[pp])\n",
    "            pp_directory = os.path.join(id_directory, erps)\n",
    "            fname = os.path.join(pp_directory, 'p%03d_SmallLarge_%s_%s_%s-ave.fif' % (participants[pp], movenames[move], 'SL', 'aln_mir'))\n",
    "            if os.path.isfile(fname) == False:\n",
    "                continue\n",
    "            evoked = mne.read_evokeds(fname)\n",
    "            evoked = evoked[0]\n",
    "            evoked = evoked.get_data(picks=channels[channel]) #will give data of shape (n_channels, n_timepts)\n",
    "            evoked = evoked[0] #get first list then index timepts below\n",
    "            evoked = evoked[200:401] #get timepts we are interested in\n",
    "            evoked_list.append(evoked)\n",
    "        if move == 0 and channel == 0:\n",
    "            alnmir_right_C3 = evoked_list\n",
    "        elif move == 0 and channel == 1:\n",
    "            alnmir_right_C4 = evoked_list\n",
    "        elif move == 1 and channel == 0:\n",
    "            alnmir_left_C3 = evoked_list\n",
    "        elif move == 1 and channel == 1:\n",
    "            alnmir_left_C4 = evoked_list\n",
    "            \n",
    "#PERTURBED CONDITIONS - only half of N in rot and mir due to considering only left and right movements\n",
    "conditionnames = ['sml', 'lrg']\n",
    "\n",
    "#ROTATED\n",
    "for condition in range(0, len(conditionnames)):\n",
    "    for channel in range(0, len(channels)):\n",
    "        for move in range(0, len(movenames)):\n",
    "            evoked_list = []\n",
    "            for pp in participants:\n",
    "                id_directory = os.path.join(data_directory, 'p%03d/' % participants[pp])\n",
    "                pp_directory = os.path.join(id_directory, erps)\n",
    "                fname = os.path.join(pp_directory, 'p%03d_SmallLarge_%s_%s_%s-ave.fif' % (participants[pp], movenames[move], conditionnames[condition], 'rot'))\n",
    "                if os.path.isfile(fname) == False:\n",
    "                    continue\n",
    "                evoked = mne.read_evokeds(fname)\n",
    "                evoked = evoked[0]\n",
    "                evoked = evoked.get_data(picks=channels[channel]) #will give data of shape (n_channels, n_timepts)\n",
    "                evoked = evoked[0] #get first list then index timepts below\n",
    "                evoked = evoked[200:401] #get timepts we are interested in\n",
    "                evoked_list.append(evoked)\n",
    "            if move == 0 and channel == 0 and condition == 0:\n",
    "                rot_small_right_C3 = evoked_list\n",
    "            elif move == 1 and channel == 0 and condition == 0:\n",
    "                rot_small_left_C3 = evoked_list\n",
    "            elif move == 0 and channel == 1 and condition == 0:\n",
    "                rot_small_right_C4 = evoked_list\n",
    "            elif move == 1 and channel == 1 and condition == 0:\n",
    "                rot_small_left_C4 = evoked_list\n",
    "            elif move == 0 and channel == 0 and condition == 1:\n",
    "                rot_large_right_C3 = evoked_list\n",
    "            elif move == 1 and channel == 0 and condition == 1:\n",
    "                rot_large_left_C3 = evoked_list\n",
    "            elif move == 0 and channel == 1 and condition == 1:\n",
    "                rot_large_right_C4 = evoked_list\n",
    "            elif move == 1 and channel == 1 and condition == 1:\n",
    "                rot_large_left_C4 = evoked_list\n",
    "\n",
    "#MIRROR\n",
    "for condition in range(0, len(conditionnames)):\n",
    "    for channel in range(0, len(channels)):\n",
    "        for move in range(0, len(movenames)):\n",
    "            evoked_list = []\n",
    "            for pp in participants:\n",
    "                id_directory = os.path.join(data_directory, 'p%03d/' % participants[pp])\n",
    "                pp_directory = os.path.join(id_directory, erps)\n",
    "                fname = os.path.join(pp_directory, 'p%03d_SmallLarge_%s_%s_%s-ave.fif' % (participants[pp], movenames[move], conditionnames[condition], 'mir'))\n",
    "                if os.path.isfile(fname) == False:\n",
    "                    continue\n",
    "                evoked = mne.read_evokeds(fname)\n",
    "                evoked = evoked[0]\n",
    "                evoked = evoked.get_data(picks=channels[channel]) #will give data of shape (n_channels, n_timepts)\n",
    "                evoked = evoked[0] #get first list then index timepts below\n",
    "                evoked = evoked[200:401] #get timepts we are interested in\n",
    "                evoked_list.append(evoked)\n",
    "            if move == 0 and channel == 0 and condition == 0:\n",
    "                mir_small_right_C3 = evoked_list\n",
    "            elif move == 1 and channel == 0 and condition == 0:\n",
    "                mir_small_left_C3 = evoked_list\n",
    "            elif move == 0 and channel == 1 and condition == 0:\n",
    "                mir_small_right_C4 = evoked_list\n",
    "            elif move == 1 and channel == 1 and condition == 0:\n",
    "                mir_small_left_C4 = evoked_list\n",
    "            elif move == 0 and channel == 0 and condition == 1:\n",
    "                mir_large_right_C3 = evoked_list\n",
    "            elif move == 1 and channel == 0 and condition == 1:\n",
    "                mir_large_left_C3 = evoked_list\n",
    "            elif move == 0 and channel == 1 and condition == 1:\n",
    "                mir_large_right_C4 = evoked_list\n",
    "            elif move == 1 and channel == 1 and condition == 1:\n",
    "                mir_large_left_C4 = evoked_list\n",
    "\n",
    "#RANDOM\n",
    "for condition in range(0, len(conditionnames)):\n",
    "    for channel in range(0, len(channels)):\n",
    "        for move in range(0, len(movenames)):\n",
    "            evoked_list = []\n",
    "            for pp in participants:\n",
    "                id_directory = os.path.join(data_directory, 'p%03d/' % participants[pp])\n",
    "                pp_directory = os.path.join(id_directory, erps)\n",
    "                fname = os.path.join(pp_directory, 'p%03d_SmallLarge_%s_%s_%s-ave.fif' % (participants[pp], movenames[move], conditionnames[condition], 'rdm'))\n",
    "                if os.path.isfile(fname) == False:\n",
    "                    continue\n",
    "                evoked = mne.read_evokeds(fname)\n",
    "                evoked = evoked[0]\n",
    "                evoked = evoked.get_data(picks=channels[channel]) #will give data of shape (n_channels, n_timepts)\n",
    "                evoked = evoked[0] #get first list then index timepts below\n",
    "                evoked = evoked[200:401] #get timepts we are interested in\n",
    "                evoked_list.append(evoked)\n",
    "            if move == 0 and channel == 0 and condition == 0:\n",
    "                rdm_small_right_C3 = evoked_list\n",
    "            elif move == 1 and channel == 0 and condition == 0:\n",
    "                rdm_small_left_C3 = evoked_list\n",
    "            elif move == 0 and channel == 1 and condition == 0:\n",
    "                rdm_small_right_C4 = evoked_list\n",
    "            elif move == 1 and channel == 1 and condition == 0:\n",
    "                rdm_small_left_C4 = evoked_list\n",
    "            elif move == 0 and channel == 0 and condition == 1:\n",
    "                rdm_large_right_C3 = evoked_list\n",
    "            elif move == 1 and channel == 0 and condition == 1:\n",
    "                rdm_large_left_C3 = evoked_list\n",
    "            elif move == 0 and channel == 1 and condition == 1:\n",
    "                rdm_large_right_C4 = evoked_list\n",
    "            elif move == 1 and channel == 1 and condition == 1:\n",
    "                rdm_large_left_C4 = evoked_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd029703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next, we calculate LRPs: (right C3 - right C4) - (left C3 - left C4)\n",
    "\n",
    "perturbations = ['aln', 'alnrot', 'alnmir', 'rot', 'rdm', 'mir']\n",
    "conditionnames = ['sml', 'lrg']\n",
    "\n",
    "for p in range(0, len(perturbations)):\n",
    "    if p == 0:\n",
    "        rightdiff = np.subtract(aln_right_C3, aln_right_C4)\n",
    "        leftdiff = np.subtract(aln_left_C3, aln_left_C4)\n",
    "        aln_lrp = np.subtract(rightdiff, leftdiff)\n",
    "    elif p == 1:\n",
    "        rightdiff = np.subtract(alnrot_right_C3, alnrot_right_C4)\n",
    "        leftdiff = np.subtract(alnrot_left_C3, alnrot_left_C4)\n",
    "        alnrot_lrp = np.subtract(rightdiff, leftdiff)\n",
    "    elif p == 2:\n",
    "        rightdiff = np.subtract(alnmir_right_C3, alnmir_right_C4)\n",
    "        leftdiff = np.subtract(alnmir_left_C3, alnmir_left_C4)\n",
    "        alnmir_lrp = np.subtract(rightdiff, leftdiff)\n",
    "    elif p == 3:\n",
    "        for condition in range(0, len(conditionnames)):\n",
    "            if condition == 0:\n",
    "                rightdiff = np.subtract(rot_small_right_C3, rot_small_right_C4)\n",
    "                leftdiff = np.subtract(rot_small_left_C3, rot_small_left_C4)\n",
    "                small_rot_lrp = np.subtract(rightdiff, leftdiff)\n",
    "            elif condition == 1:\n",
    "                rightdiff = np.subtract(rot_large_right_C3, rot_large_right_C4)\n",
    "                leftdiff = np.subtract(rot_large_left_C3, rot_large_left_C4)\n",
    "                large_rot_lrp = np.subtract(rightdiff, leftdiff)\n",
    "    elif p == 4:\n",
    "        for condition in range(0, len(conditionnames)):\n",
    "            if condition == 0:\n",
    "                rightdiff = np.subtract(rdm_small_right_C3, rdm_small_right_C4)\n",
    "                leftdiff = np.subtract(rdm_small_left_C3, rdm_small_left_C4)\n",
    "                small_rdm_lrp = np.subtract(rightdiff, leftdiff)\n",
    "            elif condition == 1:\n",
    "                rightdiff = np.subtract(rdm_large_right_C3, rdm_large_right_C4)\n",
    "                leftdiff = np.subtract(rdm_large_left_C3, rdm_large_left_C4)\n",
    "                large_rdm_lrp = np.subtract(rightdiff, leftdiff)\n",
    "    elif p == 5:\n",
    "        for condition in range(0, len(conditionnames)):\n",
    "            if condition == 0:\n",
    "                rightdiff = np.subtract(mir_small_right_C3, mir_small_right_C4)\n",
    "                leftdiff = np.subtract(mir_small_left_C3, mir_small_left_C4)\n",
    "                small_mir_lrp = np.subtract(rightdiff, leftdiff)\n",
    "            elif condition == 1:\n",
    "                rightdiff = np.subtract(mir_large_right_C3, mir_large_right_C4)\n",
    "                leftdiff = np.subtract(mir_large_left_C3, mir_large_left_C4)\n",
    "                large_mir_lrp = np.subtract(rightdiff, leftdiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a6afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we can run cluster based permutation tests, comparing our conditions\n",
    "# Note, rot and mir conditions only have 16 participants, while aligned and random have 32\n",
    "# Hence we grab corresponding aln participants for rot and mir above\n",
    "\n",
    "# Comparing two ERP signals is just the same as taking their difference (ERP1 minus ERP2) and using this in permutation test\n",
    "def get_clust_perm_test(conditionA, conditionB, pval, n_permutations):\n",
    "    #take difference of two conditions\n",
    "    data = np.subtract(conditionA, conditionB)\n",
    "    np.shape(data)\n",
    "    #define cluster forming threshold based on p-value\n",
    "    df = len(participants) - 1\n",
    "    thresh = scipy.stats.t.ppf(1 - pval / 2, df)\n",
    "    #run cluster-based permutation test\n",
    "    T_0, clust_idx, clust_pvals, H0 = mne.stats.permutation_cluster_1samp_test(data, threshold = thresh, \n",
    "                                                          n_permutations = n_permutations, tail = 0, \n",
    "                                                          adjacency = None, seed = 999, \n",
    "                                                          out_type = 'mask', verbose = True)\n",
    "\n",
    "    return T_0, clust_idx, clust_pvals, H0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724e6978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing participants between rotation and mirror would be an independent samples comparison\n",
    "# permutation function should be modified\n",
    "# F dist used here, but oneway F test = independent t test when dealing with two independent conditions only\n",
    "def get_ind_clust_perm_test(conditionA, conditionB, pval, n_permutations, n_conditions = 2):\n",
    "    #define cluster forming threshold based on p-value\n",
    "    dfn = n_conditions - 1  # degrees of freedom numerator\n",
    "    dfd = len(participants) - n_conditions  # degrees of freedom denominator\n",
    "    thresh = scipy.stats.f.ppf(1 - pval, dfn=dfn, dfd=dfd)  \n",
    "    #run cluster-based permutation test\n",
    "    F_0, clust_idx, clust_pvals, H0 = mne.stats.permutation_cluster_test([conditionA, conditionB], threshold = thresh, \n",
    "                                                          n_permutations = n_permutations, tail = 0, \n",
    "                                                          adjacency = None, seed = 999, \n",
    "                                                          out_type = 'mask', verbose = True)\n",
    "\n",
    "    return F_0, clust_idx, clust_pvals, H0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75917f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we can compare each condition to aligned. Note that rot and mir have different aln conditions\n",
    "# Generate a data frame to tabulate condition, cluster indices, cluster timepts, p values\n",
    "# This information can then be included in ERP plots\n",
    "\n",
    "# RANDOM\n",
    "flists = [small_rdm_lrp, large_rdm_lrp]\n",
    "conditionnames = ['smallrdm', 'largerdm']\n",
    "p = 0.05\n",
    "perms = 1000\n",
    "\n",
    "condition = []\n",
    "clust_idx_start = []\n",
    "clust_idx_end = []\n",
    "time_start = []\n",
    "time_end = []\n",
    "p_values = []\n",
    "\n",
    "for f in range(0, len(flists)):\n",
    "    T_0, clust_idx, clust_pvals, H0 = get_clust_perm_test(flists[f], aln_lrp, p, perms)\n",
    "#     print(clust_idx, clust_pvals)\n",
    "    if len(clust_idx) == 0:\n",
    "        condition.append(conditionnames[c])\n",
    "        clust_idx_start.append(np.nan)\n",
    "        clust_idx_end.append(np.nan)\n",
    "        time_start.append(np.nan)\n",
    "        time_end.append(np.nan)\n",
    "        p_values.append(np.nan)\n",
    "    else:\n",
    "        for clust in range(0, len(clust_idx)):\n",
    "            cluster = clust_idx[clust][0] #to get the slice sequence we need\n",
    "        \n",
    "            cluster_start = cluster.start\n",
    "            clust_idx_start.append(cluster_start)\n",
    "        \n",
    "            cluster_end = cluster.stop\n",
    "            clust_idx_end.append(cluster_end)\n",
    "        \n",
    "            time_idx_start = time[cluster_start]\n",
    "            time_start.append(time_idx_start)\n",
    "        \n",
    "            time_idx_end = time[cluster_end - 1] #minus one because python indexing does not include ending value\n",
    "            time_end.append(time_idx_end)\n",
    "        \n",
    "            clust_p = clust_pvals[clust]\n",
    "            p_values.append(clust_p)\n",
    "        \n",
    "            condition.append(conditionnames[f])\n",
    "\n",
    "# ROTATION\n",
    "participants = [0,1,2,3,8,9,10,11,16,17,18,19,24,25,26,27] #need to specify pp IDs we need\n",
    "flists = [small_rot_lrp, large_rot_lrp]\n",
    "conditionnames = ['smallrot', 'largerot']\n",
    "\n",
    "for f in range(0, len(flists)):\n",
    "    T_0, clust_idx, clust_pvals, H0 = get_clust_perm_test(flists[f], alnrot_lrp, p, perms)\n",
    "#     print(clust_idx, clust_pvals)\n",
    "    if len(clust_idx) == 0:\n",
    "        condition.append(conditionnames[c])\n",
    "        clust_idx_start.append(np.nan)\n",
    "        clust_idx_end.append(np.nan)\n",
    "        time_start.append(np.nan)\n",
    "        time_end.append(np.nan)\n",
    "        p_values.append(np.nan)\n",
    "    else:\n",
    "        for clust in range(0, len(clust_idx)):\n",
    "            cluster = clust_idx[clust][0] #to get the slice sequence we need\n",
    "        \n",
    "            cluster_start = cluster.start\n",
    "            clust_idx_start.append(cluster_start)\n",
    "        \n",
    "            cluster_end = cluster.stop\n",
    "            clust_idx_end.append(cluster_end)\n",
    "        \n",
    "            time_idx_start = time[cluster_start]\n",
    "            time_start.append(time_idx_start)\n",
    "        \n",
    "            time_idx_end = time[cluster_end - 1] #minus one because python indexing does not include ending value\n",
    "            time_end.append(time_idx_end)\n",
    "        \n",
    "            clust_p = clust_pvals[clust]\n",
    "            p_values.append(clust_p)\n",
    "        \n",
    "            condition.append(conditionnames[f])\n",
    "\n",
    "# MIRROR            \n",
    "participants = [4,5,6,7,12,13,14,15,20,21,22,23,28,29,30,31] #need to specify pp IDs we need\n",
    "flists = [small_mir_lrp, large_mir_lrp]\n",
    "conditionnames = ['smallmir', 'largemir']\n",
    "\n",
    "for f in range(0, len(flists)):\n",
    "    T_0, clust_idx, clust_pvals, H0 = get_clust_perm_test(flists[f], alnmir_lrp, p, perms)\n",
    "#     print(clust_idx, clust_pvals)\n",
    "    if len(clust_idx) == 0:\n",
    "        condition.append(conditionnames[c])\n",
    "        clust_idx_start.append(np.nan)\n",
    "        clust_idx_end.append(np.nan)\n",
    "        time_start.append(np.nan)\n",
    "        time_end.append(np.nan)\n",
    "        p_values.append(np.nan)\n",
    "    else:\n",
    "        for clust in range(0, len(clust_idx)):\n",
    "            cluster = clust_idx[clust][0] #to get the slice sequence we need\n",
    "        \n",
    "            cluster_start = cluster.start\n",
    "            clust_idx_start.append(cluster_start)\n",
    "        \n",
    "            cluster_end = cluster.stop\n",
    "            clust_idx_end.append(cluster_end)\n",
    "        \n",
    "            time_idx_start = time[cluster_start]\n",
    "            time_start.append(time_idx_start)\n",
    "        \n",
    "            time_idx_end = time[cluster_end - 1] #minus one because python indexing does not include ending value\n",
    "            time_end.append(time_idx_end)\n",
    "        \n",
    "            clust_p = clust_pvals[clust]\n",
    "            p_values.append(clust_p)\n",
    "        \n",
    "            condition.append(conditionnames[f])\n",
    "        \n",
    "perm_test = pd.DataFrame(\n",
    "    {'condition': condition,\n",
    "     'clust_idx_start': clust_idx_start,\n",
    "     'clust_idx_end': clust_idx_end,\n",
    "     'time_start': time_start,\n",
    "     'time_end': time_end,\n",
    "     'p_values': p_values})\n",
    "\n",
    "perm_test_filename = os.path.join('F:/Documents/Science/MirRevAdaptEEG/data/', 'Permutation_test_vsAligned_SmallLarge_%s.csv' % (erps))\n",
    "perm_test.to_csv(perm_test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6b70d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we subtract aligned from each condition, so that we can compare small vs large in each perturbation type\n",
    "diffconds = ['smallrot', 'largerot', 'smallrdm', 'largerdm', 'smallmir', 'largemir']\n",
    "smallrot_diff = []\n",
    "largerot_diff = []\n",
    "smallrdm_diff = []\n",
    "largerdm_diff = []\n",
    "smallmir_diff = []\n",
    "largemir_diff = []\n",
    "\n",
    "for cond in range(0, len(diffconds)):\n",
    "    if cond == 0:\n",
    "        diffevks = np.subtract(small_rot_lrp, alnrot_lrp)\n",
    "        smallrot_diff.append(diffevks)\n",
    "        smallrot_diff = smallrot_diff[0] #to keep shape of object consistent\n",
    "    elif cond == 1:\n",
    "        diffevks = np.subtract(large_rot_lrp, alnrot_lrp)\n",
    "        largerot_diff.append(diffevks)\n",
    "        largerot_diff = largerot_diff[0]\n",
    "    elif cond == 2:\n",
    "        diffevks = np.subtract(small_rdm_lrp, aln_lrp)\n",
    "        smallrdm_diff.append(diffevks)\n",
    "        smallrdm_diff = smallrdm_diff[0]\n",
    "    elif cond == 3:\n",
    "        diffevks = np.subtract(large_rdm_lrp, aln_lrp)\n",
    "        largerdm_diff.append(diffevks)\n",
    "        largerdm_diff = largerdm_diff[0]\n",
    "    elif cond == 4:\n",
    "        diffevks = np.subtract(small_mir_lrp, alnmir_lrp)\n",
    "        smallmir_diff.append(diffevks)\n",
    "        smallmir_diff = smallmir_diff[0]\n",
    "    elif cond == 5:\n",
    "        diffevks = np.subtract(large_mir_lrp, alnmir_lrp)\n",
    "        largemir_diff.append(diffevks)\n",
    "        largemir_diff =largemir_diff[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09775298",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate a data frame to tabulate condition, cluster indices, cluster timepts, p values of SMALL vs LARGE comparisons\n",
    "# This information can then be included in ERP difference wave plots\n",
    "\n",
    "conds = ['rot_diff', 'rdm_diff', 'mir_diff']\n",
    "conditionnames = ['rot', 'rdm', 'mir']\n",
    "p = 0.05\n",
    "perms = 1000\n",
    "\n",
    "condition = []\n",
    "clust_idx_start = []\n",
    "clust_idx_end = []\n",
    "time_start = []\n",
    "time_end = []\n",
    "p_values = []\n",
    "\n",
    "for c in range(0, len(conds)):\n",
    "    if c == 0:\n",
    "        participants = [0,1,2,3,8,9,10,11,16,17,18,19,24,25,26,27]\n",
    "        T_0, clust_idx, clust_pvals, H0 = get_clust_perm_test(largerot_diff, smallrot_diff, p, perms)\n",
    "#         print(clust_idx, clust_pvals)\n",
    "        if len(clust_idx) == 0:\n",
    "            condition.append(conditionnames[c])\n",
    "            clust_idx_start.append(np.nan)\n",
    "            clust_idx_end.append(np.nan)\n",
    "            time_start.append(np.nan)\n",
    "            time_end.append(np.nan)\n",
    "            p_values.append(np.nan)\n",
    "        else:\n",
    "            for clust in range(0, len(clust_idx)):\n",
    "                cluster = clust_idx[clust][0] #to get the slice sequence we need\n",
    "        \n",
    "                cluster_start = cluster.start\n",
    "                clust_idx_start.append(cluster_start)\n",
    "        \n",
    "                cluster_end = cluster.stop\n",
    "                clust_idx_end.append(cluster_end)\n",
    "        \n",
    "                time_idx_start = time[cluster_start]\n",
    "                time_start.append(time_idx_start)\n",
    "        \n",
    "                time_idx_end = time[cluster_end - 1] #minus one because python indexing does not include ending value\n",
    "                time_end.append(time_idx_end)\n",
    "        \n",
    "                clust_p = clust_pvals[clust]\n",
    "                p_values.append(clust_p)\n",
    "        \n",
    "                condition.append(conditionnames[c])\n",
    "            \n",
    "    elif c == 1:\n",
    "        participants = list(range(0,32))\n",
    "        T_0, clust_idx, clust_pvals, H0 = get_clust_perm_test(largerdm_diff, smallrdm_diff, p, perms)\n",
    "        if len(clust_idx) == 0:\n",
    "            condition.append(conditionnames[c])\n",
    "            clust_idx_start.append(np.nan)\n",
    "            clust_idx_end.append(np.nan)\n",
    "            time_start.append(np.nan)\n",
    "            time_end.append(np.nan)\n",
    "            p_values.append(np.nan)\n",
    "        else:    \n",
    "            for clust in range(0, len(clust_idx)):\n",
    "                cluster = clust_idx[clust][0] #to get the slice sequence we need\n",
    "        \n",
    "                cluster_start = cluster.start\n",
    "                clust_idx_start.append(cluster_start)\n",
    "        \n",
    "                cluster_end = cluster.stop\n",
    "                clust_idx_end.append(cluster_end)\n",
    "        \n",
    "                time_idx_start = time[cluster_start]\n",
    "                time_start.append(time_idx_start)\n",
    "        \n",
    "                time_idx_end = time[cluster_end - 1] #minus one because python indexing does not include ending value\n",
    "                time_end.append(time_idx_end)\n",
    "        \n",
    "                clust_p = clust_pvals[clust]\n",
    "                p_values.append(clust_p)\n",
    "        \n",
    "                condition.append(conditionnames[c])\n",
    "            \n",
    "    elif c == 2:\n",
    "        participants = [4,5,6,7,12,13,14,15,20,21,22,23,28,29,30,31]\n",
    "        T_0, clust_idx, clust_pvals, H0 = get_clust_perm_test(largemir_diff, smallmir_diff, p, perms)\n",
    "        if len(clust_idx) == 0:\n",
    "            condition.append(conditionnames[c])\n",
    "            clust_idx_start.append(np.nan)\n",
    "            clust_idx_end.append(np.nan)\n",
    "            time_start.append(np.nan)\n",
    "            time_end.append(np.nan)\n",
    "            p_values.append(np.nan)\n",
    "        else:    \n",
    "            for clust in range(0, len(clust_idx)):\n",
    "                cluster = clust_idx[clust][0] #to get the slice sequence we need\n",
    "        \n",
    "                cluster_start = cluster.start\n",
    "                clust_idx_start.append(cluster_start)\n",
    "        \n",
    "                cluster_end = cluster.stop\n",
    "                clust_idx_end.append(cluster_end)\n",
    "        \n",
    "                time_idx_start = time[cluster_start]\n",
    "                time_start.append(time_idx_start)\n",
    "        \n",
    "                time_idx_end = time[cluster_end - 1] #minus one because python indexing does not include ending value\n",
    "                time_end.append(time_idx_end)\n",
    "        \n",
    "                clust_p = clust_pvals[clust]\n",
    "                p_values.append(clust_p)\n",
    "        \n",
    "                condition.append(conditionnames[c])\n",
    "        \n",
    "perm_test = pd.DataFrame(\n",
    "    {'condition': condition,\n",
    "     'clust_idx_start': clust_idx_start,\n",
    "     'clust_idx_end': clust_idx_end,\n",
    "     'time_start': time_start,\n",
    "     'time_end': time_end,\n",
    "     'p_values': p_values})\n",
    "\n",
    "perm_test_filename = os.path.join('F:/Documents/Science/MirRevAdaptEEG/data/', 'Permutation_test_SmallvsLarge_%s.csv' % (erps))\n",
    "perm_test.to_csv(perm_test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255d0e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next step is to subtract small from large condition, to generate a single signal for each perturbation\n",
    "diffconds = ['rot', 'rdm', 'mir']\n",
    "rot_diff = []\n",
    "rdm_diff = []\n",
    "mir_diff = []\n",
    "\n",
    "for cond in range(0, len(diffconds)):\n",
    "    if cond == 0:\n",
    "        diffevks = np.subtract(largerot_diff, smallrot_diff)\n",
    "        rot_diff.append(diffevks)\n",
    "        rot_diff = rot_diff[0] #to keep shape of object consistent\n",
    "    elif cond == 1:\n",
    "        diffevks = np.subtract(largerdm_diff, smallrdm_diff)\n",
    "        rdm_diff.append(diffevks)\n",
    "        rdm_diff = rdm_diff[0]\n",
    "    elif cond == 2:\n",
    "        diffevks = np.subtract(largemir_diff, smallmir_diff)\n",
    "        mir_diff.append(diffevks)\n",
    "        mir_diff = mir_diff[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6ef8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a data frame to tabulate condition, cluster indices, cluster timepts, p values of PERTURBATION comparisons\n",
    "# This information can then be included in ERP difference wave plots\n",
    "\n",
    "conds = ['rotvmir', 'rotvrdm', 'mirvrdm']\n",
    "conditionnames = ['rotvmir', 'rotvrdm', 'mirvrdm']\n",
    "p = 0.05\n",
    "perms = 1000\n",
    "\n",
    "condition = []\n",
    "clust_idx_start = []\n",
    "clust_idx_end = []\n",
    "time_start = []\n",
    "time_end = []\n",
    "p_values = []\n",
    "\n",
    "for c in range(0, len(conds)):\n",
    "    if c == 0:\n",
    "        participants = list(range(0,32)) # rot plus mir participants gives N = 32\n",
    "        F_0, clust_idx, clust_pvals, H0 = get_ind_clust_perm_test(rot_diff, mir_diff, p, perms)\n",
    "#         print(clust_idx, clust_pvals)\n",
    "        if len(clust_idx) == 0:\n",
    "            condition.append(conditionnames[c])\n",
    "            clust_idx_start.append(np.nan)\n",
    "            clust_idx_end.append(np.nan)\n",
    "            time_start.append(np.nan)\n",
    "            time_end.append(np.nan)\n",
    "            p_values.append(np.nan)\n",
    "        else:\n",
    "            for clust in range(0, len(clust_idx)):\n",
    "                cluster = clust_idx[clust][0] #to get the slice sequence we need\n",
    "        \n",
    "                cluster_start = cluster.start\n",
    "                clust_idx_start.append(cluster_start)\n",
    "        \n",
    "                cluster_end = cluster.stop\n",
    "                clust_idx_end.append(cluster_end)\n",
    "        \n",
    "                time_idx_start = time[cluster_start]\n",
    "                time_start.append(time_idx_start)\n",
    "        \n",
    "                time_idx_end = time[cluster_end - 1] #minus one because python indexing does not include ending value\n",
    "                time_end.append(time_idx_end)\n",
    "        \n",
    "                clust_p = clust_pvals[clust]\n",
    "                p_values.append(clust_p)\n",
    "        \n",
    "                condition.append(conditionnames[c])\n",
    "            \n",
    "    elif c == 1:\n",
    "        #random has 32 N but rotation has 16, get corresponding participants in rdm\n",
    "        participants = [0,1,2,3,8,9,10,11,16,17,18,19,24,25,26,27]\n",
    "        rdm_subdat = [v for i,v in enumerate(rdm_diff) if i in participants]\n",
    "        T_0, clust_idx, clust_pvals, H0 = get_clust_perm_test(rot_diff, rdm_subdat, p, perms)\n",
    "        if len(clust_idx) == 0:\n",
    "            condition.append(conditionnames[c])\n",
    "            clust_idx_start.append(np.nan)\n",
    "            clust_idx_end.append(np.nan)\n",
    "            time_start.append(np.nan)\n",
    "            time_end.append(np.nan)\n",
    "            p_values.append(np.nan)\n",
    "        else:\n",
    "            for clust in range(0, len(clust_idx)):\n",
    "                cluster = clust_idx[clust][0] #to get the slice sequence we need\n",
    "        \n",
    "                cluster_start = cluster.start\n",
    "                clust_idx_start.append(cluster_start)\n",
    "        \n",
    "                cluster_end = cluster.stop\n",
    "                clust_idx_end.append(cluster_end)\n",
    "        \n",
    "                time_idx_start = time[cluster_start]\n",
    "                time_start.append(time_idx_start)\n",
    "        \n",
    "                time_idx_end = time[cluster_end - 1] #minus one because python indexing does not include ending value\n",
    "                time_end.append(time_idx_end)\n",
    "        \n",
    "                clust_p = clust_pvals[clust]\n",
    "                p_values.append(clust_p)\n",
    "        \n",
    "                condition.append(conditionnames[c])\n",
    "            \n",
    "    elif c == 2:\n",
    "        #random has 32 N but mirror has 16, get corresponding participants in rdm\n",
    "        participants = [4,5,6,7,12,13,14,15,20,21,22,23,28,29,30,31]\n",
    "        rdm_subdat = [v for i,v in enumerate(rdm_diff) if i in participants]\n",
    "        T_0, clust_idx, clust_pvals, H0 = get_clust_perm_test(mir_diff, rdm_subdat, p, perms)\n",
    "        if len(clust_idx) == 0:\n",
    "            condition.append(conditionnames[c])\n",
    "            clust_idx_start.append(np.nan)\n",
    "            clust_idx_end.append(np.nan)\n",
    "            time_start.append(np.nan)\n",
    "            time_end.append(np.nan)\n",
    "            p_values.append(np.nan)\n",
    "        else:\n",
    "            for clust in range(0, len(clust_idx)):\n",
    "                cluster = clust_idx[clust][0] #to get the slice sequence we need\n",
    "        \n",
    "                cluster_start = cluster.start\n",
    "                clust_idx_start.append(cluster_start)\n",
    "        \n",
    "                cluster_end = cluster.stop\n",
    "                clust_idx_end.append(cluster_end)\n",
    "        \n",
    "                time_idx_start = time[cluster_start]\n",
    "                time_start.append(time_idx_start)\n",
    "        \n",
    "                time_idx_end = time[cluster_end - 1] #minus one because python indexing does not include ending value\n",
    "                time_end.append(time_idx_end)\n",
    "        \n",
    "                clust_p = clust_pvals[clust]\n",
    "                p_values.append(clust_p)\n",
    "        \n",
    "                condition.append(conditionnames[c])\n",
    "        \n",
    "perm_test = pd.DataFrame(\n",
    "    {'condition': condition,\n",
    "     'clust_idx_start': clust_idx_start,\n",
    "     'clust_idx_end': clust_idx_end,\n",
    "     'time_start': time_start,\n",
    "     'time_end': time_end,\n",
    "     'p_values': p_values})\n",
    "\n",
    "perm_test_filename = os.path.join('F:/Documents/Science/MirRevAdaptEEG/data/', 'Permutation_test_SmallLarge_PerturbTypeComp_%s.csv' % (erps))\n",
    "perm_test.to_csv(perm_test_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mne]",
   "language": "python",
   "name": "conda-env-mne-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
