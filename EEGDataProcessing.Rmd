---
title: "EEG data processing using MNE-Python"
output: html_notebook
---

# Overview

This document discusses the analysis pipeline for the experiment's EEG data. We have written custom Python scripts to preprocess, organize, and analyze the data set according to our defined conditions.

# Downloading data

First, we need to ensure that the data is available locally. Both behavioral and EEG data are available on OSF. You may run the code below to download the data.

```{r}
# Uncomment the lines below to download the data:
# getBehaviorData()
# getEEGData()
```

# EEG data pre-processing

##  MirRevAdapt_Preprocessing_Funcs.py

### Instructions for Python script

We used MNE-Python to pre-process and analyze the data. As such, certain dependencies called in the Python scripts will rely on having MNE installed.

Our custom code implements the pre-processing steps described below. The user simply has to run the script to start pre-processing the EEG data. Note that with the amount of data within and across participants, along with the ICA fitting procedure, pre-processing will take several hours per participant. As such, we have saved the pre-processed epochs as part of the data downloaded, in case the user would want to skip this step.

### Triggers

Multiple events across trial types, and within each trial, correspond to unique EEG triggers (expressed as 5 digit integers below). A complete description of the trial events and trial types are found in our manuscript's Methods section.

#### Triggers across trial types
The different trial types are: resting state (16148), aligned reaches (16149), first block of random rotation (16150), rotation training (16151), washout following rotation training (16152), second block of random rotation (16153), mirror reversal training (16154), washout following mirror training (16155). There is also a trigger at the end of the block for each trial type (16156).

#### Triggers within a trial
Within each trial, the triggers correspond to trial onset (16138), target onset (16139), go signal (16140), reach onset (16141), feedback onset (16142), feedback at home (16143), fixation onset (16144).

#### Triggers for target locations
Each target location across the workspace also corresponds to its own trigger. Each target is positioned in one of four quadrants, at a set distance from the vertical or horizontal midline axis. The list of all possible target locations and their triggers are found below:

Quadrant 1:  
Vertical, near: 16164;
Vertical, mid 16165;
Vertical, far: 16166

Horizontal, near: 16158;
Horizontal, mid: 16159;
Horizontal, far 16160

Quadrant 2:  
Vertical, near: 16184;
Vertical, mid: 16185;
Vertical, far: 16186

Horizontal, near: 16178;
Horizontal, mid: 16179;
Horizontal, far: 16180

Quadrant 3:  
Vertical, near: 16167;
Vertical, mid: 16168;
Vertical, far: 16169

Horizontal, near: 16161;
Horizontal, mid: 16162;
Horizontal, far 16163

Quadrant 4:  
Vertical, near: 16187;
Vertical, mid: 16188;
Vertical, far: 16189

Horizontal, near: 16181;
Horizontal, mid: 16182;
Horizontal, far: 16183

### Pre-processing steps

We collected data using a 32-channel BioSemi ActiveTwo system. Data were sampled at 512 Hz. Electrodes are positioned according to the international 10-20 system. We used the left and right mastoids as reference electrodes. We then applied a high-pass filter at 0.1 Hz, a low-pass filter at 200 Hz, and a notch filter at 60, 120, 180, and 240 Hz. Epochs were defined by aligning data to a specific event. As we are interested in EEG activity before and after the reaching movement, we aligned data to either the go signal onset (pre-movement) or the feedback onset (post-movement), and defined each epoch's time window to range 2 seconds before and after the event. 

For artifact removal, we fit an Independent Component Analysis (ICA; extended infomax with 1000 iterations) to the epoched data. We then used the ICLabel method to label the different output components. With this method, each component label is identified as coming from the brain, eye movements, or other artifacts with a corresponding probability. For our study, we only included components labelled as "brain" and "other" with a probability of greater than 80%. The other components either did not reach this threshold or were labelled as eye, muscle or other movement artifacts. Thus, we removed these artifacts when applying the ICA to the EEG data.

Finally, we downsampled the EEG data to 200 Hz. and generated pre-processed epochs for each participant across all their trials.


# Behavior data pre-processing

We then split the epochs into different conditions, dependent on participants' behavioral performance throughout the experiment.

### data split: trial types
First, we split the data according to trial types. That is, we compared behavioral and EEG data across these trial types: aligned reaches, random rotation trials, rotation training, and mirror reversal training.

### data split: early versus late training
We are interested in investigating how learning progresses throughout perturbation training. As such, we expect that participants should perform movements with more errors at the beginning of training, compared to later on in training. While we observe no learning or a more or less stable magnitude of errors for the aligned and random rotation trials, we do observe a reduction of errors for both rotation and mirror reversal trials. Thus, we split the epoched data into early training (first two blocks of training: 12 trials) and late training (last six blocks of training: 36 trials) for the rotation and mirror trial types. Given that the random rotation is introduced in two separate blocks prior to the rotation and mirror trials, we combined both blocks as they do not show differences in performance. From this combined set of trials, the first two blocks (12 trials) are considered as early training, while the last 4 blocks (24 trials) are considered as late training. Finally, since the aligned trials do not show any changes across trials, we used all 48 trials for analyses. 

### data split: small versus large errors




















