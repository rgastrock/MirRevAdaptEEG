---
title: "ERP analyses for mirror and rotation adaptation"
author: "Raphael Q. Gastrock"
date: "2024-04-19"
output:
  pdf_document:
    toc: true
    toc_depth: '2'
  # html_document:
  #   toc: true
  #   toc_depth: 1
  #   toc_float: true
---

This document shows plots and analyses related to feedback error processing and movement preparation for different perturbation types: fixed rotation, mirror reversal, random rotation.

```{r, warning=FALSE, message=FALSE}
source('ana/shared.R')
source('ana/learningRates.R')
source('ana/errorSizesERP.R')
source('ana/directionMoves.R')
source('ana/p3analysis.R')
source('ana/permutationTtest.R')
```

First, we can see how participants performed in the different trial types, by plotting their reach performance.

```{r}
plotExperimentLearningCurves()
```

We then use the behavioral data to index corresponding epochs in the eeg data. We do this in two ways. First, we either split the epochs according to early or late learning. For example, we consider the first 45 trials in fixed rotation training as early and the last 45 trials as late. We do the same early/ late data split for the random and mirror perturbation conditions. Second, we split the epochs depending on whether the error in a given trial is considered small or large. To do this, we sort the trial errors according to magnitude. Then, we get the lowest 40% and highest 40% of errors per participant, and categorize these as either small or large error sizes. The corresponding eeg epoch is then indexed accordingly.

We focus on two time points in each trial. The first is during feedback error processing (time-locked to feedback onset), and the second is during movement preparation (time-locked to go signal onset).

# Feedback error processing

We find a negative-going component just prior to the feedback onset, but after movement onset. Given that we had continuous feedback of the cursor, this is likely similar to the feedback-related negativity (FRN), which is typically observed after an error is encountered. For simplicity, we will refer to the observed component as FRN.

## FRN: Early vs. Late learning - Figures

First, we investigate whether the FRN in early and late conditions for each perturbation, differ from the aligned or baseline reaches.

```{r}
plotEarlyLateERPs()
```

We observe that in the rotation perturbation, early trials have a more negative peak than aligned trials, while late trials seem more comparable to aligned. We do not observe a difference between random early and late trials, but both conditions have more negative peaks compared to aligned. Finally, in the mirror perturbation, late trials seem to be more negative than both early and aligned, which is opposite to what we find in fixed rotation trials.

## FRN: Early vs. Late learning - Statistics

I still have to take care of this. I tried running a permutation based t-test, where for every time point, a t-test is conducted to compare two conditions. For example, if we have 200 timepoints around the peak negativity for aligned, and 200 for early rotation, then this will output 200 p-values. We get significant p-values around the time of the peak, but this does not survive multiplicity correction. I tried bonferroni and fdr to adjust p-values. It could be that these are too conservative, and we may need to run cluster-based permutation.

Alternatively, I can calculate the minimum values per participant (peak negativity), and then run a t-test comparing two conditions. But, these produce inconclusive BF values.
```{r}
testPeakAmplitude(g1='aln', g2='earlyrot')
testPeakAmplitude(g1='aln', g2='laterot')
testPeakAmplitude(g1='aln', g2='earlyrdm')
testPeakAmplitude(g1='aln', g2='laterdm')
testPeakAmplitude(g1='aln', g2='earlyrdm')
testPeakAmplitude(g1='aln', g2='laterdm')
```

Of course, after comparing each condition with the aligned, we would need to compare early vs. late (using difference waves). Then finally, we would also compare across perturbation types. So below is an outline of statistical analyses to conduct:

1) Compare each condition (early and late OR small and large) to aligned, within each perturbation. Ideally, a permutation type of analysis is run so that we could identify the different time points that two signals are different.

2) Calculate difference waves between each condition and aligned (e.g. early rotation minus aligned; I already have this, just did not report here). Then next step is to compare early vs. rot within each condition.

3) Compare across perturbations. Perhaps we could just find the peak of the component for each perturbation type, then do an ANOVA. For example, an ANOVA comparing peak negativity across early rot, early rdm, early mir.

## P3: Early vs. Late learning - Figures

After feedback onset, we also look into the P3 component. P3 has two sub-components: P3a (150-280 ms post feedback onset) and P3b (280 - 500 ms post feedback onset). P3a is related to attention allocation, while P3b is associated with context updating, depending on the stimuli that is encountered in the environment.

```{r}
plotEarlyLateP3()
```

For the fixed rotation, both early and late show more positive P3a components than the aligned condition. However, it seems that only late condition shows a more positive P3b component that the aligned and early conditions.

For the random perturbation, both early and late show more positive P3a components than aligned, but there seems to be no difference for the P3b component.

For the mirror perturbation, both early and late show slightly more positive P3a components than aligned, but these are likely not significant. No differences in P3b.

## FRN: Small vs. Large errors - Figures

```{r}
plotSmallLargeERPs()
```

When considering error magnitude, it seems that the FRN does not scale to error magnitude for the fixed rotation. However, both error conditions are more negative than the aligned condition. We find the same patterns for the random perturbation.

For the mirror perturbation, we observe that large errors show a more nagtive FRN than aligned, but small errors are more comparable to the aligned condition.

## P3: Small vs. Large errors - Figures

```{r}
plotSmallLargeP3()
```

We do not observe differences for both P3a and P3b components in the fixed rotation.

Both error conditions, however, show more positive P3a components compared to aligned in the random perturbation.

Interestingly, for the mirror perturbation, small errors show more positive P3a and P3b components.

# Movement preparation

## LRP: Early vs. Late learning - Figures

For movement preparation, we observed the Readiness Potential just before the go signal onset. To account for lateralization of left and right movements, we calculated for a lateralized readiness potential.

LRP = (right C3 - right C4) - (left C3 - left C4)

We can then plot these differences for each condition and compare to aligned reaches.

```{r}
plotEarlyLateLateralized()
```

For the rotation perturbation, we find that both early and late LRPs are more positive than aligned.

For the random perturbation, it seems that the late LRP becomes more negative than the early LRP just before the go signal onset. 

For the mirror perturbation, although the early LRP seems more positive, the difference is unlikely to be statistically significant.

## LRP: Small vs. Large errors - Figures

```{r}
plotSmallLargeLateralized()
```

Both error conditions show more positive LRPs than the aligned condition, for both rotation and random perturbations.However, we do not observe such a difference for the mirror perturbation.
